import Foundation
import NaturalLanguage

struct ReflectionAnalysis {
  let summary: String
  let emotionTags: [String]
}

enum ReflectionAnalyzer {
  private static let prompts = [
    "ì˜¤ëŠ˜ ê°€ì¥ ì—ë„ˆì§€ê°€ ë†’ì•˜ë˜ ìˆœê°„ì€ ì–¸ì œì˜€ë‚˜ìš”?",
    "ì˜¤ëŠ˜ ë‚˜ë¥¼ ê°€ì¥ ì§€ì¹˜ê²Œ í•œ ìˆœê°„ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?",
    "ì˜¤ëŠ˜ì˜ ë‚˜ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì¹­ì°¬í•œë‹¤ë©´?",
    "ì˜¤ëŠ˜ ê°€ì¥ ì˜¤ë˜ ë‚¨ì„ ì¥ë©´ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "ì§€ê¸ˆ ê°ì •ì„ ë§Œë“  ì‚¬ê±´ í•˜ë‚˜ë¥¼ ì ì–´ë³´ì„¸ìš”."
  ]

  private static let emotionRules: [(tag: String, keywords: [String])] = [
    ("ì•ˆì •", ["í‰ì˜¨", "ì°¨ë¶„", "í¸ì•ˆ", "ì•ˆì •", "ì—¬ìœ "]),
    ("ê¸°ì¨", ["í–‰ë³µ", "ê¸°ì¨", "ì›ƒ", "ì„¤ë ˜", "ì¦ê±°", "ë¿Œë“¯"]),
    ("ê°ì‚¬", ["ê°ì‚¬", "ê³ ë§ˆ", "ë“ ë“ ", "ë”°ëœ»"]),
    ("í”¼ë¡œ", ["í”¼ê³¤", "ì§€ì¹¨", "ì§€ì³¤", "ë¬´ê¸°ë ¥", "ì¡¸ë¦¼", "ë²„ê²"]),
    ("ë¶ˆì•ˆ", ["ë¶ˆì•ˆ", "ê±±ì •", "ì´ˆì¡°", "ê¸´ì¥", "ì••ë°•", "ë¶€ë‹´", "ë§‰ë§‰"]),
    ("ë¶„ë…¸", ["í™”", "ì§œì¦", "ë¶„ë…¸", "ë‹µë‹µ", "ì–µìš¸", "ë¹¡ì¹¨", "ë©ì²­", "êµ¬ë ¤"]),
    ("ìŠ¬í””", ["ìŠ¬í””", "ìš°ìš¸", "ëˆˆë¬¼", "ì™¸ë¡­", "í—ˆë¬´"]),
    ("ì§‘ì¤‘", ["ëª°ì…", "ì§‘ì¤‘", "ì„±ì·¨", "í•´ëƒˆ", "ì™„ë£Œ"])
  ]

  private static let stopwords: Set<String> = [
    "ê·¸ë¦¬ê³ ", "ê·¸ëŸ¬ë‚˜", "í•˜ì§€ë§Œ", "ê·¸ë˜ì„œ", "ê·¸ëŸ°ë°", "ì •ë§", "ì§„ì§œ", "ê·¸ëƒ¥", "ë„ˆë¬´", "ì¡°ê¸ˆ",
    "ì˜¤ëŠ˜", "ì–´ì œ", "ë‚´ì¼", "ì§€ê¸ˆ", "ì´ì œ", "ì´ê±°", "ì €ê±°", "ê·¸ê±°", "ë‚´ìš©", "ë¶€ë¶„", "ìƒí™©",
    "ë¬¸ì œ", "ìƒê°", "ê¸°ë¶„", "ë•Œë¬¸", "ê´€ë ¨", "ëŒ€í•œ", "ìœ„í•´", "ì—ì„œ", "ìœ¼ë¡œ", "ì—ê²Œ", "í–ˆë‹¤", "í•˜ëŠ”"
  ]

  private static let issueHints = ["ì™œ", "ë¬¸ì œ", "í•œê³„", "ì„±ëŠ¥", "ì˜¤ë¥˜", "ì‹¤íŒ¨", "ì•ˆë¨", "ì•ˆë¼", "ë¶€ë‹´"]

  static func prompt(excluding current: String? = nil) -> String {
    if prompts.isEmpty { return "ì˜¤ëŠ˜ ê°€ì¥ ì˜¤ë˜ ë‚¨ì„ ì¥ë©´ì€ ë¬´ì—‡ì¸ê°€ìš”?" }
    if let current, prompts.count > 1 {
      let candidates = prompts.filter { $0 != current }
      return candidates.randomElement() ?? prompts[0]
    }
    return prompts.randomElement() ?? prompts[0]
  }

  static func analyze(content: String, mood: String?) -> ReflectionAnalysis {
    let cleaned = normalize(content)
    guard !cleaned.isEmpty else {
      return ReflectionAnalysis(summary: "ì˜¤ëŠ˜ ê¸°ë¡ì´ ì§§ì•„ í•µì‹¬ ìš”ì•½ì„ ë§Œë“¤ê¸° ì–´ë ¤ì›€", emotionTags: [])
    }

    let sentences = extractSentences(from: cleaned)
    let main = pickMainSentence(from: sentences, source: cleaned)
    let context = pickContextSentence(from: sentences, excluding: main)

    var detected = detectEmotionTags(in: cleaned)
    if let mood, let moodTag = moodTag(from: mood) {
      detected.append(moodTag)
    }
    let uniqueTags = orderedUnique(detected)

    let summary = buildOneLineSummary(main: main, context: context, emotionTag: uniqueTags.first)
    return ReflectionAnalysis(summary: summary, emotionTags: uniqueTags)
  }

  private static func moodTag(from mood: String) -> String? {
    switch mood {
    case "ğŸ¥°", "ğŸ˜Š", "ğŸ¥³":
      return "ê¸ì •"
    case "ğŸ˜”":
      return "ì¹¨ì "
    case "ğŸ˜¡":
      return "ê²©ì–‘"
    case "ğŸ˜´":
      return "ì €ì—ë„ˆì§€"
    case "ğŸ¤¯":
      return "ê³¼ë¶€í•˜"
    default:
      return nil
    }
  }

  private static func buildOneLineSummary(main: String, context: String?, emotionTag: String?) -> String {
    var line = clipped(main, limit: 72)

    if let context, !context.isEmpty {
      line += "; " + clipped(context, limit: 46)
    }

    if let emotionTag, !emotionTag.isEmpty {
      line += " (\(emotionTag))"
    }

    return normalizedSummaryLine(line)
  }

  private static func pickMainSentence(from sentences: [String], source: String) -> String {
    guard !sentences.isEmpty else { return source }
    let frequencies = tokenFrequency(from: source)

    let ranked = sentences.map { sentence -> (sentence: String, score: Double) in
      let tokens = wordTokens(from: sentence)
      let keywordScore = tokens.reduce(0.0) { partial, token in
        partial + Double(frequencies[token] ?? 0)
      }
      let uniqueBonus = tokens.isEmpty ? 0.0 : Double(Set(tokens).count) / Double(tokens.count)
      let hintBonus = issueHints.contains(where: { sentence.localizedCaseInsensitiveContains($0) }) ? 1.2 : 0.0
      let lengthBonus = (sentence.count >= 14 && sentence.count <= 90) ? 0.2 : -0.1
      return (sentence, keywordScore + uniqueBonus + hintBonus + lengthBonus)
    }
    .sorted { $0.score > $1.score }

    return ranked.first?.sentence ?? sentences[0]
  }

  private static func pickContextSentence(from sentences: [String], excluding main: String) -> String? {
    guard sentences.count > 1 else { return nil }
    let mainTokenSet = Set(wordTokens(from: main))

    for sentence in sentences where sentence != main {
      let candidateSet = Set(wordTokens(from: sentence))
      if jaccard(mainTokenSet, candidateSet) < 0.72 {
        return sentence
      }
    }

    return sentences.first(where: { $0 != main })
  }

  private static func detectEmotionTags(in text: String) -> [String] {
    var detected: [String] = []
    for rule in emotionRules {
      if rule.keywords.contains(where: { text.localizedCaseInsensitiveContains($0) }) {
        detected.append(rule.tag)
      }
    }
    return detected
  }

  private static func extractSentences(from text: String) -> [String] {
    var sentences: [String] = []
    let tokenizer = NLTokenizer(unit: .sentence)
    tokenizer.string = text

    tokenizer.enumerateTokens(in: text.startIndex..<text.endIndex) { range, _ in
      let sentence = String(text[range]).trimmingCharacters(in: .whitespacesAndNewlines)
      let cleaned = stripTrailingPunctuation(sentence)
      if !cleaned.isEmpty {
        sentences.append(cleaned)
      }
      return true
    }

    if !sentences.isEmpty { return sentences }

    return text
      .components(separatedBy: CharacterSet(charactersIn: ".!?ã€‚ï¼ï¼Ÿ\n"))
      .map { stripTrailingPunctuation($0.trimmingCharacters(in: .whitespacesAndNewlines)) }
      .filter { !$0.isEmpty }
  }

  private static func tokenFrequency(from text: String) -> [String: Int] {
    var result: [String: Int] = [:]
    for token in wordTokens(from: text) {
      result[token, default: 0] += 1
    }
    return result
  }

  private static func wordTokens(from text: String) -> [String] {
    var tokens: [String] = []
    let tokenizer = NLTokenizer(unit: .word)
    tokenizer.string = text

    tokenizer.enumerateTokens(in: text.startIndex..<text.endIndex) { range, _ in
      let token = String(text[range]).lowercased()
      if isMeaningfulToken(token) {
        tokens.append(token)
      }
      return true
    }
    return tokens
  }

  private static func isMeaningfulToken(_ token: String) -> Bool {
    guard token.count >= 2 else { return false }
    if stopwords.contains(token) { return false }
    if token.allSatisfy({ $0.isNumber }) { return false }
    return token.rangeOfCharacter(from: CharacterSet.letters) != nil
  }

  private static func orderedUnique(_ values: [String]) -> [String] {
    var seen: Set<String> = []
    var result: [String] = []
    for value in values where !seen.contains(value) {
      seen.insert(value)
      result.append(value)
    }
    return result
  }

  private static func jaccard(_ lhs: Set<String>, _ rhs: Set<String>) -> Double {
    guard !(lhs.isEmpty && rhs.isEmpty) else { return 1.0 }
    let intersection = lhs.intersection(rhs).count
    let union = lhs.union(rhs).count
    guard union > 0 else { return 0.0 }
    return Double(intersection) / Double(union)
  }

  private static func normalize(_ text: String) -> String {
    text
      .replacingOccurrences(of: "\n", with: " ")
      .replacingOccurrences(of: "\t", with: " ")
      .components(separatedBy: .whitespacesAndNewlines)
      .filter { !$0.isEmpty }
      .joined(separator: " ")
      .trimmingCharacters(in: .whitespacesAndNewlines)
  }

  private static func stripTrailingPunctuation(_ text: String) -> String {
    text.trimmingCharacters(in: CharacterSet(charactersIn: ".!?ã€‚ï¼ï¼Ÿ ").union(.whitespacesAndNewlines))
  }

  private static func clipped(_ text: String, limit: Int) -> String {
    guard text.count > limit else { return text }
    return String(text.prefix(limit)) + "..."
  }

  private static func normalizedSummaryLine(_ text: String) -> String {
    let compact = text
      .replacingOccurrences(of: "\n", with: " ")
      .components(separatedBy: .whitespacesAndNewlines)
      .filter { !$0.isEmpty }
      .joined(separator: " ")
      .trimmingCharacters(in: .whitespacesAndNewlines)

    if compact.hasSuffix(".") || compact.hasSuffix("!") || compact.hasSuffix("?") {
      return compact
    }
    return compact + "."
  }
}
